from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
import google.generativeai as genai
from PIL import Image
import docx
from docx.shared import Pt, RGBColor
from docx.oxml.ns import qn
from docx.oxml import OxmlElement
import pypdf
import io
import os
import time
import random
import re
from datetime import datetime
from typing import List, Optional, Dict, Any
import json
from pydantic import BaseModel
import base64

app = FastAPI(title="Personal Statement Writing API", version="1.0.0")

# Environment variables
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, replace with frontend URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. æ•°æ®æ¨¡å‹
# ==========================================
class GenerationRequest(BaseModel):
    api_key: str
    model_name: str = "gemini-2.5-pro"
    target_school_name: str
    counselor_strategy: str = ""
    selected_modules: List[str]
    spelling_preference: str = "British"  # "British" or "American"
    material_text: Optional[str] = None
    # Files will be handled separately as multipart form data

class FileUploadRequest(BaseModel):
    api_key: str
    model_name: str = "gemini-2.5-pro"
    target_school_name: str
    counselor_strategy: str = ""
    selected_modules: List[str]
    spelling_preference: str = "British"
    material_file: Optional[UploadFile] = None
    transcript_file: Optional[UploadFile] = None
    curriculum_text: Optional[str] = None
    curriculum_files: Optional[List[UploadFile]] = None

class TranslationRequest(BaseModel):
    api_key: str = ""
    model_name: str = "gemini-2.5-pro"
    chinese_text: str
    spelling_preference: str = "British"
    module_type: str  # "Motivation", "Academic", etc.

class EditRequest(BaseModel):
    api_key: str = ""
    model_name: str = "gemini-2.5-pro"
    text: str
    is_chinese: bool = True

class WordGenerationRequest(BaseModel):
    content: str
    header_text: str
    is_chinese: bool = False
    font_name: str = "å®‹ä½“"

# ==========================================
# 2. æ ¸å¿ƒè¾…åŠ©å‡½æ•° (ä»åŸ psw.py ç§»æ¤)
# ==========================================
def set_bottom_border(paragraph):
    """ä¸ºæ®µè½æ·»åŠ ä¸‹æ¡†çº¿ (ç”¨äºé¡µçœ‰)"""
    p = paragraph._p
    pPr = p.get_or_add_pPr()
    pBdr = OxmlElement('w:pBdr')
    bottom = OxmlElement('w:bottom')
    bottom.set(qn('w:val'), 'single')
    bottom.set(qn('w:sz'), '6') # 1/8 pt, 6 = 0.75pt
    bottom.set(qn('w:space'), '1')
    bottom.set(qn('w:color'), '000000') # é»‘è‰²
    pBdr.append(bottom)
    pPr.append(pBdr)

def create_word_docx(content, header_text, font_name, is_chinese=False):
    """ç”Ÿæˆ Word æ–‡æ¡£ (åŒ…å«æ¸…æ´—é€»è¾‘)"""
    doc = docx.Document()

    # --- 1. è®¾ç½®é¡µçœ‰ ---
    section = doc.sections[0]
    header = section.header

    # è·å–é¡µçœ‰çš„ç¬¬ä¸€ä¸ªæ®µè½ï¼ˆé»˜è®¤å­˜åœ¨ï¼‰
    header_para = header.paragraphs[0]
    header_para.text = header_text
    header_para.alignment = docx.enum.text.WD_ALIGN_PARAGRAPH.LEFT

    # è®¾ç½®é¡µçœ‰ä¸‹æ¡†çº¿
    set_bottom_border(header_para)

    # è®¾ç½®é¡µçœ‰å­—ä½“æ ·å¼ (12pt, æ–œä½“)
    for run in header_para.runs:
        run.font.name = font_name
        run.font.size = Pt(12)
        run.font.italic = True
        # å¤„ç†ä¸­æ–‡å­—ä½“æ˜¾ç¤º
        if is_chinese:
            run._element.rPr.rFonts.set(qn('w:eastAsia'), font_name)

    # --- 2. è®¾ç½®æ­£æ–‡ (æ¸…æ´—é€»è¾‘ä¼˜åŒ–) ---
    # 1. å»é™¤ Markdown åŠ ç²—ç¬¦å·
    content = content.replace("**", "")
    # 2. å»é™¤ Markdown å•æ˜Ÿå· (åˆ—è¡¨æˆ–æ–œä½“)
    content = content.replace("*", "")

    # æŒ‰è¡Œå¤„ç†
    for line in content.split('\n'):
        line = line.strip()

        # 3. è·³è¿‡ç©ºè¡Œ
        if not line:
            continue

        # 4. ğŸš¨ æ ¸å¿ƒä¿®æ”¹ï¼šè·³è¿‡æ®µè½æ ‡é¢˜è¡Œ (ç‰¹å¾ï¼šä»¥ --- å¼€å¤´)
        # ç¡®ä¿åªä¿ç•™æ­£æ–‡ï¼Œç§»é™¤ç±»ä¼¼ "--- Motivation ---" æˆ– "--- ç”³è¯·åŠ¨æœº ---" çš„è¡Œ
        if line.startswith("---") and line.endswith("---"):
            continue

        p = doc.add_paragraph(line)
        # è®¾ç½®æ­£æ–‡æ ·å¼ (11pt)
        for run in p.runs:
            run.font.name = font_name
            run.font.size = Pt(11)
            # å¤„ç†ä¸­æ–‡å­—ä½“æ˜¾ç¤º
            if is_chinese:
                run._element.rPr.rFonts.set(qn('w:eastAsia'), font_name)

    # ä¿å­˜åˆ°å†…å­˜
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

def read_word_file(file_bytes):
    """è¯»å– Word æ–‡ä»¶å†…å®¹"""
    try:
        doc = docx.Document(io.BytesIO(file_bytes))
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)
        return '\n'.join(full_text)
    except Exception as e:
        return f"Error reading Word file: {e}"

def read_pdf_text(file_bytes):
    """è¯»å– PDF æ–‡ä»¶å†…å®¹"""
    try:
        pdf_reader = pypdf.PdfReader(io.BytesIO(file_bytes))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Error reading PDF file: {e}"

def get_gemini_response(api_key: str, model_name: str, prompt: str, media_content=None, text_context=None):
    """è°ƒç”¨ Gemini API"""
    # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„API Key
    effective_api_key = GOOGLE_API_KEY if GOOGLE_API_KEY else api_key
    if not effective_api_key:
        return "Error: API Key is required. Please set GOOGLE_API_KEY environment variable or provide via request."

    genai.configure(api_key=effective_api_key)
    model = genai.GenerativeModel(model_name)

    content = []
    content.append(prompt)

    if text_context:
        content.append(f"\nã€å‚è€ƒæ–‡æ¡£/èƒŒæ™¯ä¿¡æ¯ (ç®€å†æˆ–ç´ æè¡¨)ã€‘:\n{text_context}")

    if media_content:
        if isinstance(media_content, list):
            content.extend(media_content)
        else:
            content.append(media_content)

    try:
        response = model.generate_content(content)
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

# ==========================================
# 3. æç¤ºè¯æ¨¡æ¿ (ä»åŸ psw.py ç§»æ¤)
# ==========================================
CLEAN_OUTPUT_RULES = """
ã€ç»å¯¹è¾“å‡ºè§„åˆ™ã€‘
1. åªè¾“å‡ºæ­£æ–‡å†…å®¹æœ¬èº«ã€‚
2. ä¸¥ç¦åŒ…å«å¼€åœºç™½ã€ç»“å°¾è¯­æˆ–ç»“æ„è¯´æ˜ã€‚
3. ä¸¥ç¦ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¦‚åŠ ç²—ã€åˆ—è¡¨ç¬¦å·ã€æ ‡é¢˜ç¬¦å·ï¼‰ã€‚
4. è¾“å‡ºå¿…é¡»æ˜¯çº¯æ–‡æœ¬ã€‚
5. å¿…é¡»å†™æˆä¸€ä¸ªå®Œæ•´çš„ã€è¿è´¯çš„ä¸­æ–‡è‡ªç„¶æ®µã€‚
"""

TRANSLATION_RULES_BASE = """
ã€Translation Taskã€‘
Translate the provided Chinese text into a professional, human-sounding Personal Statement paragraph.

ã€CRITICAL ANTI-AI STYLE GUIDEã€‘
1. **KILL THE "AI SENTENCE PATTERN"**:
   - **ABSOLUTELY FORBIDDEN**: The pattern "I did X, **thereby/thus/enabling** me to do Y."
   - **SOLUTION**: Split into two sentences or use active verbs.

2. **SEMICOLONS (;) FOR FLOW**:
   - **MANDATORY**: When a sentence is grammatically complete but the thought is not finished (and leads directly into the next point), use a **semicolon (;)** to connect them.

3. **ADVERB CONTROL (ZERO TOLERANCE)**:
   - **STRICTLY PROHIBITED**: The combination of **Adverb + Verb** (e.g., "deeply analyze", "successfully completed") OR **Adverb + Adjective** (e.g., "perfectly align", "keenly interested").
   - **ACTION**: Delete the adverb entirely. Just use the verb or adjective.

4. **VOCABULARY PURGE**:
   - Use precise, simple words.

5. **ENHANCE COHESION & NARRATIVE FLOW (CRITICAL)**:
   - **MANDATORY**: You MUST actively add varied transitional phrases and logical connectors (e.g., "Furthermore," "In contrast," "Consequently," "Given this context") between sentences AND between paragraphs.
   - **GOAL**: Ensure the text flows smoothly as a unified narrative, not a disjointed list of sentences. The priority is reading fluency and the overall integrity of the article.

ã€BANNED WORDS LIST (Strictly Prohibited)ã€‘
[Verbs]: delve into, uncover, reveal, recognize, master, refine, cultivate, address, bridge, spearhead, pioneer, align with, stems from, underscore, highlight
[Adjectives/Adverbs]: instrumental, pivotal, seamless, systematically, rigorously, profoundly, deeply, acutely, keenly, comprehensively, perfectly, meticulously, proficiency, Additionally
[Nouns]: paradigm, trajectory, aspirations, vision, landscape, tapestry, realm, foundation, tenure, testament, commitment
[Connectors]: thereby, thus (when used with -ing), in turn
[Phrases]: "not only... but also", "Building on this", "rich tapestry", "testament to", "a wide array of", "my goal is to"ï¼Œ "focus will be"

ã€Formattingã€‘
1. Output as ONE single paragraph.
2. Output the ENTIRE text in **Bold**.
3. No Markdown headers.
"""

def get_prompt_motivation(target_school_name: str) -> str:
    return f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ Personal Statement çš„ "ç”³è¯·åŠ¨æœº" éƒ¨åˆ†ã€‚
    ã€æ­¥éª¤ 1ï¼šæ·±åº¦è°ƒç ”ã€‘
    è¯·å…ˆåˆ†æ {target_school_name} æ‰€åœ¨é¢†åŸŸçš„æœ€æ–°è¡Œä¸šçƒ­ç‚¹æˆ–å­¦æœ¯è¶‹åŠ¿ã€‚
    **è¯·ä¸¥æ ¼åˆ—å‡º 3 ä¸ªå…³é”®è¶‹åŠ¿ (Options)**ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ **HTML æ ¼å¼** è¾“å‡ºï¼ˆé™¤æ–‡çŒ®/æŠ¥å‘Šæ ‡é¢˜ä¿ç•™åŸæ–‡å¤–ï¼Œå…¶ä½™åˆ†æå†…å®¹è¯·ä½¿ç”¨**ä¸­æ–‡**ï¼‰ï¼š

    <div style="margin-bottom: 18px;">
        <div style="font-weight: bold; font-size: 14px; margin-bottom: 6px;">Option [X]: [Trend Title]</div>
        <ul style="margin: 0; padding-left: 18px; list-style-position: outside;">
            <li style="margin-bottom: 4px; line-height: 1.4;"><b>Source</b>: [Specific Paper Title/Report Name/News Source]</li>
            <li style="line-height: 1.4;"><b>Relevance</b>: [æ·±åº¦åˆ†æè¶‹åŠ¿ä¸å­¦ç”ŸèƒŒæ™¯/é¡¹ç›®çš„å…³è”ã€‚è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªè¶‹åŠ¿å¯¹è¯¥å­¦ç”Ÿé‡è¦ï¼Œä»¥åŠä»–ä»¬ä¹‹å‰çš„ç»å†ï¼ˆå¦‚å…·ä½“é¡¹ç›®ã€æŠ€èƒ½ï¼‰å¦‚ä½•ä¸æ­¤å¥‘åˆã€‚æ­¤éƒ¨åˆ†å¿…é¡»è¯¦ç»†å±•å¼€ã€‚]</li>
        </ul>
    </div>

    ã€æ­¥éª¤ 2ï¼šæ’°å†™æ­£æ–‡ã€‘
    åŸºäºä¸Šè¿°è¶‹åŠ¿å’Œå­¦ç”Ÿç´ æï¼Œæ’°å†™ä¸€æ®µä¸­æ–‡ç”³è¯·åŠ¨æœºã€‚åŠ¨æœºæ­£æ–‡ä¸­ä¸ç”¨å‡ºç°å…·ä½“ä¿¡æ¯æºï¼Œä½†è¦ä½“ç°å‡ºå­¦ç”Ÿå¯¹è¡Œä¸šè¶‹åŠ¿çš„ç†è§£å’Œå¥‘åˆã€‚
    é€»è¾‘ï¼šå­¦ç”Ÿè¿‡å¾€ç»å† -> è§‚å¯Ÿåˆ°çš„è¡Œä¸šç—›ç‚¹/è¶‹åŠ¿ -> äº§ç”Ÿæ·±é€ éœ€æ±‚ã€‚
    ã€ä¸¥æ ¼è¾“å‡ºæ ¼å¼ã€‘
    è¯·ä¸¥æ ¼æŒ‰ç…§ä¸‹æ–¹åˆ†éš”ç¬¦è¾“å‡ºï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ï¼š
    [TRENDS_START]
    (åœ¨æ­¤å¤„åˆ—å‡º 3 ä¸ªè°ƒç ”è¶‹åŠ¿å’Œæ¥æºï¼Œä½¿ç”¨ä¸Šè¿° HTML æ ¼å¼)
    [TRENDS_END]
    [DRAFT_START]
    (åœ¨æ­¤å¤„æ’°å†™æ­£æ–‡æ®µè½ï¼Œçº¯æ–‡æœ¬ï¼Œæ— Markdown)
    [DRAFT_END]
    """

def get_prompt_career(target_school_name: str, counselor_strategy: str) -> str:
    return f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "èŒä¸šè§„åˆ’" (Career Goals) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    - é¡¾é—®æ€è·¯: {counselor_strategy}
    ã€å†…å®¹è¦æ±‚ã€‘
    1. è§„åˆ’ç¡•å£«æ¯•ä¸šåçš„è·¯å¾„ï¼ˆåº”å±Šç”Ÿè§†è§’ï¼‰ã€‚
    2. **å¿…é¡»åŒ…å«**ï¼šå…·ä½“çš„å…¬å¸åå­—ã€å…·ä½“çš„èŒä½åç§°ã€‚
    3. å°†å·¥ä½œå†…å®¹å’Œæœªæ¥ç»§ç»­å­¦ä¹ æ–¹å‘èåˆåœ¨ä¸€æ®µè¯ä¸­ã€‚
    {CLEAN_OUTPUT_RULES}
    """

def get_prompt_academic(target_school_name: str) -> str:
    return f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "æœ¬ç§‘å­¦ä¹ ç»å†" (Academic Background) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    - æ ¸å¿ƒä¾æ® (æˆç»©å•): è§é™„å¸¦æ–‡ä»¶ (PDFæˆ–å›¾ç‰‡)
    - è¾…åŠ©å‚è€ƒ (å­¦ç”Ÿç´ æ/ç®€å†): è§é™„å¸¦æ–‡æœ¬
    ã€æ ¸å¿ƒåŸåˆ™ï¼šæ·±åº¦ > æ•°é‡ã€‘
    ä¸è¦ç½—åˆ—è¯¾ç¨‹åã€‚åªç²¾é€‰ä¸ç›®æ ‡ä¸“ä¸šæœ€å¼ºç›¸å…³çš„æ ¸å¿ƒè¯¾ç¨‹è¿›è¡Œæ·±åº¦æå†™ã€‚
    ã€å†…å®¹è¦æ±‚ - å¿…é¡»åŒ…å«ç»†èŠ‚ã€‘
    1. **æ ¸å¿ƒæ¦‚å¿µæ¤å…¥**ï¼šåœ¨æè¿°æ¯é—¨è¯¾æ—¶ï¼Œå¿…é¡»æåŠè¯¥è¯¾ç¨‹å…·ä½“çš„**æ ¸å¿ƒæ¦‚å¿µã€æ¨¡å‹ã€ç®—æ³•æˆ–ç†è®ºåç§°**ã€‚
    2. **å­¦æœ¯çœŸå®æ„Ÿ**ï¼šç»“åˆå­¦ç”Ÿç´ æï¼Œç®€è¿°æ˜¯å¦‚ä½•ç†è§£æˆ–åº”ç”¨è¿™äº›æ¦‚å¿µçš„ã€‚
    3. **é€»è¾‘å‡å**ï¼šè¯´æ˜è¿™äº›å…·ä½“çš„çŸ¥è¯†ç‚¹å¦‚ä½•ä¸ºä½ æ”»è¯» {target_school_name} æ‰“ä¸‹äº†åšå®çš„å­¦æœ¯åŸºç¡€ã€‚
    4. **ç¦æ­¢**ï¼šç¦æ­¢å†™æˆè¯¾ç¨‹æ¸…å•ï¼ˆListï¼‰ï¼Œå¿…é¡»æ˜¯è¿è´¯çš„å­¦æœ¯åæ€å™è¿°ã€‚
    {CLEAN_OUTPUT_RULES}
    """

def get_prompt_whyschool(target_school_name: str, counselor_strategy: str, target_curriculum_text: str) -> str:
    return f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "Why School" éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡å­¦æ ¡: {target_school_name}
    - é¡¾é—®æ€è·¯: {counselor_strategy}
    {f'ã€ç›®æ ‡è¯¾ç¨‹æ–‡æœ¬åˆ—è¡¨ã€‘:{target_curriculum_text}' if target_curriculum_text else ''}
    - è¯¾ç¨‹å›¾ç‰‡ä¿¡æ¯: è§é™„å¸¦å›¾ç‰‡
    ã€å†…å®¹è¦æ±‚ã€‘
    1. ç»¼åˆåˆ†ææä¾›çš„æ–‡æœ¬åˆ—è¡¨å’Œå›¾ç‰‡ä¸­çš„è¯¾ç¨‹ä¿¡æ¯ã€‚
    2. ä»ä¸­æŒ‘é€‰ä¸å­¦ç”ŸèƒŒæ™¯æˆ–è§„åˆ’æœ€ç›¸å…³çš„ç‰¹å®šè¯¾ç¨‹ï¼Œä¸ç›¸å…³çš„è¯¾ç¨‹ä¸ç”¨å†™ã€‚
    3. è‹¥æ‰€æä¾›ä¿¡æ¯åŒ…å«è¯¾ç¨‹åå­—ä¸è¯¾ç¨‹è¯´æ˜åˆ™å‚è€ƒï¼Œè‹¥ä»…æœ‰è¯¾ç¨‹åå­—ä½†æ— è¯¾ç¨‹è¯´æ˜åˆ™æœç´¢è¯¥è¯¾ç¨‹ï¼ˆç¡•å£«æ°´å¹³ï¼‰çš„æ•™å­¦å†…å®¹ï¼Œå¹¶æ®æ­¤é˜è¿°è¿™äº›è¯¾ç¨‹ä¸ºä½•å¸å¼•å­¦ç”ŸåŠæœ‰ä½•å¸®åŠ©ï¼Œé˜è¿°æ—¶éœ€æ·±å…¥åˆ°è¯¥è¯¾ç¨‹å…·ä½“æ•™æˆçš„æ–¹æ³•å­¦åŠæ¦‚å¿µã€‚
    4. è¯¾ç¨‹é˜è¿°éœ€æœ‰æ·±åº¦ï¼Œæœ‰é€»è¾‘é¡ºåºæˆ–éš¾åº¦é€’è¿›å…³ç³»ï¼Œä½“ç°å‡ºå¯¹è¯¾ç¨‹å†…å®¹çš„ç†è§£ï¼Œè€Œéç®€å•ç½—åˆ—è¯¾ç¨‹åç§°ã€‚
    5. è¯­æ°”æœ´ç´ ä¸“ä¸šï¼Œè®®è®ºä¸ºä¸»ã€‚
    {CLEAN_OUTPUT_RULES}
    """

def get_prompt_internship(target_school_name: str) -> str:
    return f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "å®ä¹ /å·¥ä½œç»å†" (Professional Experience) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - å­¦ç”Ÿç´ æ: è§é™„å¸¦æ–‡æœ¬
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    ã€å†…å®¹è¦æ±‚ã€‘
    1. ç­›é€‰æœ€ç›¸å…³ç»å†ï¼ŒæŒ‰æ—¶é—´é¡ºåºé€»è¾‘ä¸²è”ã€‚
    2. ç»“æ„ï¼šèƒŒæ™¯ -> èŒè´£ -> æŠ€èƒ½ -> åŠ¨æœºã€‚
    3. æ‹’ç»æµæ°´è´¦ï¼Œè¦æœ‰é€»è¾‘æ¢³ç†å’Œåæ€ï¼Œè¦æœ‰ä¸æ‰€ç”³è¯·ä¸“ä¸šçš„å¥‘åˆç‚¹å’Œç›¸å…³çš„æ„Ÿæ‚Ÿã€‚
    {CLEAN_OUTPUT_RULES}
    """

# æ¨¡å—æ˜ å°„
modules = {
    "Motivation": "ç”³è¯·åŠ¨æœº",
    "Academic": "æœ¬ç§‘å­¦ä¹ ",
    "Internship": "å®ä¹ /å·¥ä½œ",
    "Why_School": "é€‰æ ¡ç†ç”±",
    "Career_Goal": "èŒä¸šè§„åˆ’"
}

english_modules = {
    "Motivation": "Motivation",
    "Academic": "Academic Background",
    "Internship": "Professional Experience",
    "Why_School": "Why School",
    "Career_Goal": "Career Goal"
}

display_order = ["Motivation", "Academic", "Internship", "Why_School", "Career_Goal"]

# ==========================================
# 4. API ç«¯ç‚¹
# ==========================================
@app.get("/")
def read_root():
    return {"message": "Personal Statement Writing API", "status": "running"}

@app.post("/api/generate")
async def generate_personal_statement(
    api_key: str = Form(""),
    model_name: str = Form("gemini-2.5-pro"),
    target_school_name: str = Form(...),
    counselor_strategy: str = Form(""),
    selected_modules: str = Form(...),  # JSON string of list
    spelling_preference: str = Form("British"),
    material_file: Optional[UploadFile] = File(None),
    transcript_file: Optional[UploadFile] = File(None),
    curriculum_text: Optional[str] = Form(None),
    curriculum_files: Optional[List[UploadFile]] = File([]),
):
    """ç”Ÿæˆä¸ªäººé™ˆè¿°å„ä¸ªæ¨¡å—çš„å†…å®¹"""
    try:
        # Parse selected modules
        modules_list = json.loads(selected_modules)

        # Read material file
        student_background_text = ""
        if material_file:
            file_bytes = await material_file.read()
            if material_file.filename.endswith('.docx'):
                student_background_text = read_word_file(file_bytes)
            elif material_file.filename.endswith('.pdf'):
                student_background_text = read_pdf_text(file_bytes)

        # Prepare media content
        transcript_content = []
        if transcript_file:
            file_bytes = await transcript_file.read()
            if transcript_file.content_type == "application/pdf":
                transcript_content.append({
                    "mime_type": "application/pdf",
                    "data": file_bytes
                })
            else:
                # For image files
                transcript_content.append(Image.open(io.BytesIO(file_bytes)))

        curriculum_imgs = []
        if curriculum_files:
            for img_file in curriculum_files:
                file_bytes = await img_file.read()
                curriculum_imgs.append(Image.open(io.BytesIO(file_bytes)))

        # Generate content for each selected module
        generated_sections = {}
        motivation_trends = ""

        for module in modules_list:
            # Get appropriate prompt
            if module == "Motivation":
                prompt = get_prompt_motivation(target_school_name)
                current_media = None
            elif module == "Career_Goal":
                prompt = get_prompt_career(target_school_name, counselor_strategy)
                current_media = None
            elif module == "Academic":
                prompt = get_prompt_academic(target_school_name)
                current_media = transcript_content
            elif module == "Why_School":
                prompt = get_prompt_whyschool(target_school_name, counselor_strategy, curriculum_text or "")
                current_media = curriculum_imgs
            elif module == "Internship":
                prompt = get_prompt_internship(target_school_name)
                current_media = None
            else:
                continue

            # Call Gemini API
            response = get_gemini_response(
                api_key=api_key,
                model_name=model_name,
                prompt=prompt,
                media_content=current_media,
                text_context=student_background_text
            )

            final_text = response.strip()

            # Special handling for Motivation module
            if module == "Motivation":
                if "[TRENDS_START]" in response and "[DRAFT_START]" in response:
                    trends_part = response.split("[TRENDS_START]")[1].split("[TRENDS_END]")[0].strip()
                    draft_part = response.split("[DRAFT_START]")[1].split("[DRAFT_END]")[0].strip()
                    motivation_trends = trends_part
                    final_text = draft_part
                else:
                    final_text = response

            generated_sections[module] = final_text

        # Build full Chinese draft
        full_chinese_draft = ""
        for module in display_order:
            if module in generated_sections:
                full_chinese_draft += f"--- {modules[module]} ---\n"
                full_chinese_draft += generated_sections[module] + "\n\n"

        return JSONResponse(content={
            "success": True,
            "generated_sections": generated_sections,
            "full_chinese_draft": full_chinese_draft.strip(),
            "motivation_trends": motivation_trends
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Generation failed: {str(e)}")

@app.post("/api/translate")
async def translate_content(request: TranslationRequest):
    """ç¿»è¯‘ä¸­æ–‡å†…å®¹åˆ°è‹±æ–‡"""
    try:
        spelling_instruction = "\nã€SPELLING RULEã€‘: STRICTLY use British English spelling (e.g., colour, analyse, programme, centre)."
        if request.spelling_preference == "American":
            spelling_instruction = "\nã€SPELLING RULEã€‘: STRICTLY use American English spelling (e.g., color, analyze, program, center)."

        trans_prompt = f"{TRANSLATION_RULES_BASE}\n{spelling_instruction}\nã€Input Textã€‘:\n{request.chinese_text}"

        translated_text = get_gemini_response(
            api_key=request.api_key,
            model_name=request.model_name,
            prompt=trans_prompt
        )

        return JSONResponse(content={
            "success": True,
            "translated_text": translated_text.strip(),
            "module": request.module_type
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Translation failed: {str(e)}")

@app.post("/api/edit")
async def edit_content(request: EditRequest):
    """æ ¹æ®æ‰¹æ³¨ç¼–è¾‘å†…å®¹"""
    try:
        if request.is_chinese:
            inline_prompt = f"""
            ã€ä»»åŠ¡ã€‘ä½œä¸ºä¸“ä¸šç•™å­¦æ–‡ä¹¦ç¼–è¾‘ï¼Œæ ¹æ®æ–‡ä¸­çš„åµŒå…¥å¼æ‰¹æ³¨ï¼ˆä¸­æ–‡æ–¹æ‹¬å·ã€ã€‘å†…çš„æ–‡å­—ï¼‰ä¿®æ”¹æ–‡ç« ã€‚
            ã€è¾“å…¥æ–‡æœ¬ã€‘\n{request.text}
            ã€æ‰§è¡Œæ­¥éª¤ã€‘
            1. æ‰«ææ–‡ä¸­æ‰€æœ‰çš„ä¸­æ–‡æ–¹æ‹¬å· `ã€ã€‘`ã€‚æ‹¬å·å†…çš„æ–‡å­—å³ä¸ºç”¨æˆ·çš„ä¿®æ”¹æŒ‡ä»¤ã€‚
            2. æ ¹æ®æŒ‡ä»¤ï¼Œä¿®æ”¹æ‹¬å·ç´§é‚»çš„å‰æ–‡å¥å­æˆ–æ®µè½ã€‚
            3. **å¿…é¡»åˆ é™¤**åŸæ–‡ä¸­çš„æ‹¬å·åŠæ‹¬å·å†…çš„ä¿®æ”¹æŒ‡ä»¤ã€‚
            4. ä¿æŒæœªè¢«æ‰¹æ³¨çš„éƒ¨åˆ†åŸå°ä¸åŠ¨ã€‚
            5. **é«˜äº®å˜åŒ–**ï¼šå°†**æ‰€æœ‰è¢«ä¿®æ”¹åäº§ç”Ÿçš„æ–°æ–‡å­—**ç”¨ Markdown åŒæ˜Ÿå· `**` åŒ…è£¹ï¼ˆä¾‹å¦‚ï¼š**new text**ï¼‰ï¼Œä»¥ä¾¿ç”¨æˆ·ä¸€çœ¼çœ‹å‡ºæ”¹äº†å“ªé‡Œã€‚
            {CLEAN_OUTPUT_RULES}
            """
        else:
            inline_prompt = f"""
            ã€ä»»åŠ¡ã€‘ä½ æ˜¯ä¸€ä½é¡¶å°–çš„ç•™å­¦æ–‡ä¹¦ç¼–è¾‘ã€‚è¯·æ ¹æ®ç”¨æˆ·åœ¨è‹±æ–‡æ–‡æœ¬ä¸­åµŒå…¥çš„ä¸­æ–‡ï¼Œå¯¹æ–‡ç« è¿›è¡Œä¿®æ”¹å’Œæ¶¦è‰²ã€‚

            ã€è¾“å…¥æ–‡æœ¬åŠæ‰¹æ³¨ã€‘
            {request.text}

            ã€æ‰¹æ³¨è§„åˆ™è¯´æ˜ã€‘
            1.  **ä¿®æ”¹æŒ‡ä»¤ `ã€ä¸­æ–‡å†…å®¹ã€‘`**: å¦‚æœå‘ç°ä¸­æ–‡è¢«ä¸­æ–‡æ–¹æ‹¬å· `ã€ã€‘` åŒ…å›´ï¼Œè¿™ä»£è¡¨ä¸€æ¡ä¿®æ”¹æŒ‡ä»¤ã€‚è¯·æ ¹æ®æŒ‡ä»¤å†…å®¹ï¼Œä¿®æ”¹å®ƒå‰é¢çš„è‹±æ–‡å¥å­ã€‚
            2.  **ç¿»è¯‘å¹¶æ’å…¥**: å¦‚æœå‘ç°ä¸€æ®µä¸­æ–‡**æ²¡æœ‰è¢«ä»»ä½•æ‹¬å·åŒ…å›´**ï¼Œè¯·å°†è¿™æ®µä¸­æ–‡ç¿»è¯‘æˆåœ°é“çš„è‹±æ–‡ï¼Œå¹¶æ— ç¼åœ°æ’å…¥åˆ°æ–‡æœ¬çš„é‚£ä¸ªä½ç½®ã€‚

            ã€æ ¸å¿ƒé£æ ¼æŒ‡ä»¤ã€‘
            æ‰€æœ‰çš„ä¿®æ”¹å’Œç¿»è¯‘éƒ½å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ã€ANTI-AI STYLE GUIDEã€‘ã€‚
            {TRANSLATION_RULES_BASE}

            ã€è¾“å‡ºè¦æ±‚ã€‘
            1.  å®Œæˆæ‰€æœ‰ä¿®æ”¹å’Œç¿»è¯‘ã€‚
            2.  **å¿…é¡»åˆ é™¤**åŸæ–‡ä¸­æ‰€æœ‰çš„ä¸­æ–‡å†…å®¹å’Œ `ã€ã€‘` æ‹¬å·ã€‚
            3.  **å¿…é¡»ä¿ç•™**æ‰€æœ‰çš„åˆ†æ®µæ ‡é¢˜ï¼ˆä¾‹å¦‚ `--- Motivation ---`ï¼‰ã€‚
            4.  å°†**æ‰€æœ‰è¢«ä¿®æ”¹æˆ–æ–°å¢çš„è‹±æ–‡éƒ¨åˆ†**ç”¨ Markdown åŒæ˜Ÿå· `**` åŒ…è£¹ï¼Œä»¥ä¾¿ç”¨æˆ·è¯†åˆ«ã€‚
            5.  æœ€ç»ˆè¾“å‡ºå®Œæ•´çš„ã€ä¿ç•™äº†åˆ†æ®µç»“æ„çš„è‹±æ–‡æ–‡æœ¬ã€‚
            """

        edited_text = get_gemini_response(
            api_key=request.api_key,
            model_name=request.model_name,
            prompt=inline_prompt
        )

        return JSONResponse(content={
            "success": True,
            "edited_text": edited_text.strip()
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Edit failed: {str(e)}")

@app.post("/api/generate-word")
async def generate_word_document(request: WordGenerationRequest):
    """ç”ŸæˆWordæ–‡æ¡£"""
    try:
        docx_bytes = create_word_docx(
            content=request.content,
            header_text=request.header_text,
            font_name=request.font_name,
            is_chinese=request.is_chinese
        )

        # Determine filename
        if request.is_chinese:
            filename = "personal_statement_cn.docx"
        else:
            filename = "personal_statement_en.docx"

        return StreamingResponse(
            io.BytesIO(docx_bytes),
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Word generation failed: {str(e)}")

@app.post("/api/generate-header")
async def generate_header(
    api_key: str = Form(""),
    model_name: str = Form("gemini-2.5-pro"),
    target_school_name: str = Form(...)
):
    """ç”Ÿæˆä¸­è‹±æ–‡é¡µçœ‰"""
    try:
        header_prompt = f"""
        Task: Parse and format the university and major information from the string: "{target_school_name}".

        Rules:
        1. Identify the School Name and Major Name.
        2. Create a Chinese Header: [School Name (Chinese, add 'å¤§å­¦' if missing)] + [Major Name] + "ä¸ªäººé™ˆè¿°"
        3. Create an English Header: "Personal Statement for " + [Major Name (English)] + "_" + [School Name (English)]

        Example Input: å¡å†…åŸºæ¢…éš†Master's in Health Care Analytics
        Example Output: å¡å†…åŸºæ¢…éš†å¤§å­¦Master's in Health Care Analyticsä¸ªäººé™ˆè¿°|Personal Statement for Master's in Health Care Analytics_Carnegie Mellon University

        Output ONLY the two strings separated by a pipe symbol (|). Do not add any other text.
        """

        header_res = get_gemini_response(
            api_key=api_key,
            model_name=model_name,
            prompt=header_prompt
        )

        if "|" in header_res:
            parts = header_res.split("|")
            header_cn = parts[0].strip()
            header_en = parts[1].strip()
        else:
            # Fallback
            header_cn = f"{target_school_name} ä¸ªäººé™ˆè¿°"
            header_en = f"Personal Statement for {target_school_name}"

        return JSONResponse(content={
            "success": True,
            "header_cn": header_cn,
            "header_en": header_en
        })

    except Exception as e:
        return JSONResponse(content={
            "success": True,
            "header_cn": f"{target_school_name} ä¸ªäººé™ˆè¿°",
            "header_en": f"Personal Statement for {target_school_name}"
        })

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)